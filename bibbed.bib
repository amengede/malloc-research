@inproceedings{inproceedings,
author = {Masmano, M. and Ripoll, I. and Crespo, Alfons and Real, Jorge},
year = {2004},
month = {01},
pages = {79- 88},
title = {TLSF: A new dynamic memory allocator for real-time systems},
volume = {16},
isbn = {0-7695-2176-2},
journal = {Euromicro Conference on Real-Time Systems},
doi = {10.1109/EMRTS.2004.1311009}
}

@article{10.1002/spe.4380240602,
author = {Detlefs, David and Dosser, Al and Zorn, Benjamin},
title = {Memory allocation costs in large C and C++ programs},
year = {1994},
issue_date = {June 1994},
publisher = {John Wiley \& Sons, Inc.},
address = {USA},
volume = {24},
number = {6},
issn = {0038-0644},
url = {https://doi.org/10.1002/spe.4380240602},
doi = {10.1002/spe.4380240602},
journal = {Softw. Pract. Exper.},
month = {jun},
pages = {527–542},
numpages = {16},
keywords = {performance evaluation, garbage collection, dynamic storage allocation, dynamic memory management, conservative collection}
}

@book{10.5555/2025255,
author = {Jones, Richard and Hosking, Antony and Moss, Eliot},
title = {The Garbage Collection Handbook: The Art of Automatic Memory Management},
year = {2011},
isbn = {1420082795},
publisher = {Chapman \& Hall/CRC},
edition = {1st},
abstract = {Published in 1996, Richard Joness Garbage Collection was a milestone in the area of automatic memory management. The field has grown considerably since then, sparking a need for an updated look at the latest state-of-the-art developments. The Garbage Collection Handbook: The Art of Automatic Memory Management brings together a wealth of knowledge gathered by automatic memory management researchers and developers over the past fifty years. The authors compare the most important approaches and state-of-the-art techniques in a single, accessible framework. The book addresses new challenges to garbage collection made by recent advances in hardware and software. It explores the consequences of these changes for designers and implementers of high performance garbage collectors. Along with simple and traditional algorithms, the book covers parallel, incremental, concurrent, and real-time garbage collection. Algorithms and concepts are often described with pseudocode and illustrations. The nearly universal adoption of garbage collection by modern programming languages makes a thorough understanding of this topic essential for any programmer. This authoritative handbook gives expert insight on how different collectors work as well as the various issues currently facing garbage collectors. Armed with this knowledge, programmers can confidently select and configure the many choices of garbage collectors. Web ResourceThe books online bibliographic database at www.gchandbook.org includes over 2,500 garbage collection-related publications. Continually updated, it contains abstracts for some entries and URLs or DOIs for most of the electronically available ones. The database can be searched online or downloaded as BibTeX, PostScript, or PDF.}
}

Bartlett, J. (2004) Inside Memory Management, IBM developer. Available at: https://developer.ibm.com/tutorials/l-memory/ (Accessed: 19 August 2024). 

@article{10.1145/301589.286864,
author = {Johnstone, Mark S. and Wilson, Paul R.},
title = {The memory fragmentation problem: solved?},
year = {1998},
issue_date = {March 1999},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {3},
issn = {0362-1340},
url = {https://doi.org/10.1145/301589.286864},
doi = {10.1145/301589.286864},
abstract = {We show that for 8 real and varied C and C++ programs, several conventional dynamic storage allocators provide near-zero fragmentation, once we account for overheads due to implementation details such as headers, alignment, etc. This substantially strengthens our previous results showing that the memory fragmentation problem has generally been misunderstood, and that good allocator policies can provide good memory usage for most programs. The new results indicate that for most programs, excellent allocator policies are readily available, and efficiency of implementation is the major challenge. While we believe that our experimental results are state-of-the-art and our methodology is superior to most previous work, more work should be done to identify and study unusual problematic program behaviors not represented in our sample.},
journal = {SIGPLAN Not.},
month = {oct},
pages = {26–36},
numpages = {11}
}

@INPROCEEDINGS{528746,
  author={Ogasawara, T.},
  booktitle={Proceedings Second International Workshop on Real-Time Computing Systems and Applications}, 
  title={An algorithm with constant execution time for dynamic storage allocation}, 
  year={1995},
  volume={},
  number={},
  pages={21-25},
  keywords={Real time systems;High level languages;Dynamic programming;Laboratories;Processor scheduling;Programming profession;Computational modeling;Scheduling algorithm;Computer architecture;Upper bound},
  doi={10.1109/RTCSA.1995.528746}}

@misc{matani2021fastbitmapfitcpu,
  title={Fast Bitmap Fit: A CPU Cache Line friendly memory allocator for single object allocations}, 
  author={Dhruv Matani and Gaurav Menghani},
  year={2021},
  eprint={2110.10357},
  archivePrefix={arXiv},
  primaryClass={cs.DS},
  url={https://arxiv.org/abs/2110.10357}, 
}

@article{10.1145/173262.155107,
author = {Grunwald, Dirk and Zorn, Benjamin and Henderson, Robert},
title = {Improving the cache locality of memory allocation},
year = {1993},
issue_date = {June 1993},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {28},
number = {6},
issn = {0362-1340},
url = {https://doi.org/10.1145/173262.155107},
doi = {10.1145/173262.155107},
abstract = {The allocation and disposal of memory is a ubiquitous operation in most programs. Rarely do programmers concern themselves with details of memory allocators; most assume that memory allocators provided by the system perform well. This paper presents a performance evaluation of the reference locality of dynamic storage allocation algorithms based on trace-driven simualtion of five large allocation-intensive C programs. In this paper, we show how the design of a memory allocator can significantly affect the reference locality for various applications. Our measurements show that poor locality in sequential-fit allocation algorithms reduces program performance, both by increasing paging and cache miss rates. While increased paging can be debilitating on any architecture, cache misses rates are also important for modern computer architectures. We show that algorithms attempting to be space-efficient by coalescing adjacent free objects show poor reference locality, possibly negating the benefits of space efficiency. At the other extreme, algorithms can expend considerable effort to increase reference locality yet gain little in total execution performance. Our measurements suggest an allocator design that is both very fast and has good locality of reference.},
journal = {SIGPLAN Not.},
month = {jun},
pages = {177–186},
numpages = {10}
}

@inproceedings{10.1145/800217.806613,
author = {Stephenson, C. J.},
title = {New methods for dynamic storage allocation (Fast Fits)},
year = {1983},
isbn = {0897911156},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/800217.806613},
doi = {10.1145/800217.806613},
abstract = {The classical methods for implementing dynamic storage allocation can be summarized thus First Fit and Best Fit The available blocks of storage are linked together in address order. Storage is allocated from the first available block of sufficient length, or from a block with the minimum excess length. Storage can be allocated or released in multiples of two words. In the long run, if numerous pieces of storage of more-or-less random lengths are allocated and released at more-or-less random intervals, the storage becomes fragmented, and a number of uselessly small blocks develop, particularly near the beginning of the list. Although these fragments usually comprise a small proportion of the storage (typically around 10 per cent), a lot of time can be wasted chaining through them. Buddy Methods Here the task of managing the storage is reduced in size by constraining the way in which the storage can be divided up, e.g. into blocks with lengths which are powers of 2. This eliminates chaining through long lists of uselessly small blocks; on the other hand, space is wasted in rounding up the length requested to an allowable size, and typically about 40 per cent more storage is required to satisfy the same allocations than when using First Fit or Best Fit.The methods presented in this paper are externally compatible with First Fit and Best Fit, and require roughly the same amount of storage for a given sequence of allocations. They use, however, a completely different internal data structure, one effect of which is to reduce the number of blocks that have to be visited to perform a typical allocation or release operation. These new methods exhibit roughly the same space performance as First Fit, and a time performance which falls between those of First Fit and Buddy.},
booktitle = {Proceedings of the Ninth ACM Symposium on Operating Systems Principles},
pages = {30–32},
numpages = {3},
location = {Bretton Woods, New Hampshire, USA},
series = {SOSP '83}
}

@article{10.1145/358841.358852,
author = {Vuillemin, Jean},
title = {A unifying look at data structures},
year = {1980},
issue_date = {April 1980},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {4},
issn = {0001-0782},
url = {https://doi.org/10.1145/358841.358852},
doi = {10.1145/358841.358852},
abstract = {Examples of fruitful interaction between geometrical combinatorics and the design and analysis of algorithms are presented. A demonstration is given of the way in which a simple geometrical construction yields new and efficient algorithms for various searching and list manipulation problems.},
journal = {Commun. ACM},
month = {apr},
pages = {229–239},
numpages = {11},
keywords = {search, permutations, merge, linear list, dictionaries, data structures, analysis of algorithms}
}

@article{10.1145/3828.3835,
author = {Sleator, Daniel Dominic and Tarjan, Robert Endre},
title = {Self-adjusting binary search trees},
year = {1985},
issue_date = {July 1985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {32},
number = {3},
issn = {0004-5411},
url = {https://doi.org/10.1145/3828.3835},
doi = {10.1145/3828.3835},
abstract = {The splay tree, a self-adjusting form of binary search tree, is developed and analyzed. The binary search tree is a data structure for representing tables and lists so that accessing, inserting, and deleting items is easy. On an n-node splay tree, all the standard search tree operations have an amortized time bound of O(log n) per operation, where by “amortized time” is meant the time per operation averaged over a worst-case sequence of operations. Thus splay trees are as efficient as balanced trees when total running time is the measure of interest. In addition, for sufficiently long access sequences, splay trees are as efficient, to within a constant factor, as static optimum search trees. The efficiency of splay trees comes not from an explicit structural constraint, as with balanced trees, but from applying a simple restructuring heuristic, called splaying, whenever the tree is accessed. Extensions of splaying give simplified forms of two other data structures: lexicographic or multidimensional search trees and link/cut trees.},
journal = {J. ACM},
month = {jul},
pages = {652–686},
numpages = {35}
}

@book{knuth97,
  added-at = {2015-06-04T07:09:07.000+0200},
  address = {Reading, Mass.},
  author = {Knuth, Donald E.},
  biburl = {https://www.bibsonomy.org/bibtex/296a2ce8070028e53a72f4b1d64d467a5/ytyoun},
  edition = {Third},
  interhash = {bb4a4a475ed6fc749f4863d5fa9bb651},
  intrahash = {96a2ce8070028e53a72f4b1d64d467a5},
  isbn = {0201896834 9780201896831},
  keywords = {algorithm knuth no.pdf taocp textbook},
  publisher = {Addison-Wesley},
  refid = {872287313},
  timestamp = {2015-07-29T09:31:31.000+0200},
  title = {The Art of Computer Programming, Vol. 1: Fundamental Algorithms},
  year = 1997
}

@misc{ibmDeveloper,
	author = {Bartlett, Jonathan},
	title = {IBM Developer --- developer.ibm.com},
	howpublished = {\url{https://developer.ibm.com/tutorials/l-memory/}},
	year = {2004},
	note = {[Accessed 10-09-2024]},
}